{
  "tokenizer": {
    "type": "hf_gpt2tokenizerfast",
    "from_pretrained": true,
    "add_padding_token": false
  },
  "dataset": {
    "name": "enron_tfr",
    "train_path": "./data/enron_tfr/tokenized/*.tfrecords",
    "eval_path": "./data/enron_tfr/tokenized/*.tfrecords",
    "seed": 1,
    "shuffle_input_filenames": true,
    "pretokenized": true,
    "filetype": "tfrecords"
  },
  "num_epochs": 10,
  "train_steps": 572300,
  "eval_batch_size": 32,
  "learning_rate": 0.0006,
  "generate_length": 256,
  "seq_len": 1024,
  "hidden_dim": 768,
  "n_layers": 12,
  "n_heads": 12,
  "dim_head": 64,
  "checkpoint_dir": "./gpt3small",
  "train_batch_size": 256
}
